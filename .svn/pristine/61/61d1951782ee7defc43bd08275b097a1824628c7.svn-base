program supersimple;
(*
super simple example: learns boolean functions XOR, AND and OR.
Copyright (C) 2019 Joao Paulo Schwarz Schuler

This program is free software; you can redistribute it and/or modify
it under the terms of the GNU General Public License as published by
the Free Software Foundation; either version 2 of the License, or
any later version.

This program is distributed in the hope that it will be useful,
but WITHOUT ANY WARRANTY; without even the implied warranty of
MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
GNU General Public License for more details.

You should have received a copy of the GNU General Public License along
with this program; if not, write to the Free Software Foundation, Inc.,
51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA.
*)

{$mode objfpc}{$H+}

uses {$IFDEF UNIX} {$IFDEF UseCThreads}
  cthreads, {$ENDIF} {$ENDIF}
  Classes,
  uconvolutionneuralnetwork,
  uvolume;

type TBackInput  = array[0..3] of array[0..1] of TNeuralFloat;
type TBackOutput = array[0..3] of array[0..2] of TNeuralFloat;

const inputs : TBackInput =
  ( // x1,   x2
    ( 0.1,  0.1), // False, False
    ( 0.1,  0.9), // False, True
    ( 0.9,  0.1), // True,  False
    ( 0.9,  0.9)  // True,  True
  );

const reluoutputs : TBackOutput =
  (// XOR, AND,   OR
    ( 0.1, 0.1, 0.1),
    ( 0.8, 0.1, 0.8),
    ( 0.8, 0.1, 0.8),
    ( 0.1, 0.8, 0.8)
  );

  procedure RunAlgo();
  var
    NN: TNNet;
    EpochCnt: integer;
    Cnt: integer;
    pOutPut: TNNetVolume;
    vInputs: TBackInput;
    vOutput: TBackOutput;
  begin
    NN := TNNet.Create();
    NN.AddLayer( TNNetInput.Create(2) );
    NN.AddLayer( TNNetFullConnectReLU.Create(3) );
    NN.AddLayer( TNNetFullConnectReLU.Create(3) );
    NN.SetLearningRate(0.01, 0.9);

    vInputs := inputs;
    vOutput := reluoutputs;
    pOutPut := TNNetVolume.Create(3,1,1,1);

    for EpochCnt := 1 to 3000 do
    begin
      for Cnt := Low(inputs) to High(inputs) do
      begin
        NN.Compute(vInputs[cnt]);
        NN.GetOutput(pOutPut);
        NN.Backpropagate(vOutput[cnt]);
        if EpochCnt mod 300 = 0 then
        WriteLn
        (
          EpochCnt:7,'x',Cnt,
          ' Output:',
          pOutPut.Raw[0]:5:2,' ',
          pOutPut.Raw[1]:5:2,' ',
          pOutPut.Raw[2]:5:2,
          ' - Training/Desired Output:',
          vOutput[cnt][0]:5:2,' ',
          vOutput[cnt][1]:5:2,' ' ,
          vOutput[cnt][2]:5:2,' '
        );
      end;
      if EpochCnt mod 300 = 0 then WriteLn();
    end;
    NN.DebugWeights();
    NN.DebugErrors();
    pOutPut.Free;
    NN.Free;
    Write('Press ENTER to exit.');
    ReadLn;
  end;

var
  // Stops Lazarus errors
  Application: record Title:string; end;

begin
  RunAlgo();
end.
